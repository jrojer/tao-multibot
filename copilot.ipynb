{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "def _getOrThrow(key):\n",
    "    value = os.getenv(key)\n",
    "    if value is None:\n",
    "        raise RuntimeError(f\"Missing environment variable: {key}\")\n",
    "    return value\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = _getOrThrow(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "class GptCompleter:\n",
    "    def __init__(self, system_prompt: str) -> None:\n",
    "        self._system_prompt = system_prompt\n",
    "\n",
    "    def complete(self, prompt: str) -> str:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            json={\n",
    "                \"model\": \"gpt-4-0125-preview\",\n",
    "                \"max_tokens\": 4000,\n",
    "                \"temperature\": 0,\n",
    "                \"top_p\": 1,\n",
    "                \"frequency_penalty\": 0,\n",
    "                \"presence_penalty\": 0,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": self._system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "            },\n",
    "            headers={\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "            },\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT_TEPMPLATE = \"\"\"\\\n",
    "You are a programming assistant. \n",
    "\n",
    "When asked to update, please provide only the code that you want to add or change.\n",
    "\n",
    "\n",
    "Source files are:\n",
    "```\n",
    "{filenames}\n",
    "```\n",
    "\n",
    "Source code:\n",
    "\n",
    "{source_files}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SOURCE_PART_TEMPLATE = \"\"\"\\\n",
    "name: `{filename}`\n",
    "\n",
    "contents:\n",
    "```\n",
    "{contents}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "INCLUDE_SUFFIXES = [\".py\", \".md\"]\n",
    "EXCLUDE_DIRS = [\".git\", \"__pycache__\", \".venv\"]\n",
    "\n",
    "\n",
    "def all_files_recursively(dir=\".\", exclude_dirs=EXCLUDE_DIRS):\n",
    "    result = []\n",
    "    for p in Path(dir).iterdir():\n",
    "        if p.is_dir() and p.name in exclude_dirs:\n",
    "            continue\n",
    "        if p.is_file():\n",
    "            result.append(p)\n",
    "        else:\n",
    "            result.extend(all_files_recursively(p, exclude_dirs))\n",
    "    return result\n",
    "\n",
    "\n",
    "def build_sys_prompt(dir=\".\"):\n",
    "    all_files = all_files_recursively(dir)\n",
    "    filenames = [str(p.relative_to(dir)) for p in all_files]\n",
    "    parts = []\n",
    "    for p in all_files:\n",
    "        if p.suffix in INCLUDE_SUFFIXES:\n",
    "            try:\n",
    "                contents = p.read_text() or \"EMPTY FILE\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {p}: {e}\")\n",
    "                return\n",
    "            parts.append(\n",
    "                SOURCE_PART_TEMPLATE.format(\n",
    "                    filename=p.relative_to(dir), contents=contents\n",
    "                )\n",
    "            )\n",
    "    return SYSTEM_PROMPT_TEPMPLATE.format(\n",
    "        filenames=\"\\n\".join(filenames), source_files=\"\\n\".join(parts)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a programming assistant. \n",
       "\n",
       "When asked to update, please provide only the code that you want to add or change.\n",
       "\n",
       "\n",
       "Source files are:\n",
       "```\n",
       "app/src/plugins/task_manager/.keep\n",
       "app/src/plugins/pdf_reader/.keep\n",
       "app/src/server/config.py\n",
       "app/src/server/main.py\n",
       "app/src/heads/tg_bot/.keep\n",
       "app/src/heads/tg_acc/.keep\n",
       "app/src/heads/whatsapp/.keep\n",
       "LICENSE\n",
       "requirements.txt\n",
       "copilot.ipynb\n",
       "pyproject.toml\n",
       "README.md\n",
       ".gitignore\n",
       ".env\n",
       "config.yml\n",
       ".env_ex\n",
       "```\n",
       "\n",
       "Source code:\n",
       "\n",
       "name: `app/src/server/config.py`\n",
       "\n",
       "contents:\n",
       "```\n",
       "EMPTY FILE\n",
       "```\n",
       "\n",
       "name: `app/src/server/main.py`\n",
       "\n",
       "contents:\n",
       "```\n",
       "EMPTY FILE\n",
       "```\n",
       "\n",
       "name: `README.md`\n",
       "\n",
       "contents:\n",
       "```\n",
       "# tao-multibot\n",
       "LLM chat-bot infrastructure service featuring multiple bots instances with custom plugins and frontends\n",
       "\n",
       "```\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(build_sys_prompt()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "How can I assist you with your test?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QUERY = \"\"\"\\\n",
    "This is a test.\n",
    "\"\"\"\n",
    "res = GptCompleter(build_sys_prompt()).complete(QUERY)\n",
    "display(Markdown(res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
